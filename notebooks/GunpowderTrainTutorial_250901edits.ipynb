{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff9047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gunpowder as gp\n",
    "from funlib.persistence import open_ds #may need to change to ome later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa31aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare arrays to use in the pipeline\n",
    "raw = gp.ArrayKey('RAW')\n",
    "labels = gp.ArrayKey('LABELS')\n",
    "mask = gp.ArrayKey('MASK')\n",
    "gt_affs = gp.ArrayKey('GT_AFFS')\n",
    "gt_affs_mask = gp.ArrayKey('GT_AFFS_MASK')\n",
    "prediction = gp.ArrayKey('PREDICT')\n",
    "aff_scale= gp.ArrayKey(\"SCALE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ec14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_array = open_ds(\"/mnt/efs/aimbl_2025/student_data/S-EK/EK_transfer/GT_movie1/crop_1.zarr/raw\")\n",
    "labels_array = open_ds(\"/mnt/efs/aimbl_2025/student_data/S-EK/EK_transfer/GT_movie1/crop_1.zarr/labels\")\n",
    "mask_array = open_ds(\"/mnt/efs/aimbl_2025/student_data/S-EK/EK_transfer/GT_movie1/crop_1.zarr/mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4b6446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 170, 170)\n",
      "(1000, 170, 170)\n",
      "(1000, 170, 170)\n"
     ]
    }
   ],
   "source": [
    "print(raw_array.voxel_size)\n",
    "print(labels_array.voxel_size)\n",
    "print(mask_array.voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f710ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"pipeline\" consisting only of a data source\n",
    "source_raw = gp.ArraySource( key= raw, array= raw_array, interpolatable= True)\n",
    "source_labels = gp.ArraySource( key= labels, array= labels_array, interpolatable= False)\n",
    "source_mask = gp.ArraySource( key= mask, array= mask_array, interpolatable= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acdc8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_location = gp.RandomLocation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e76b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = gp.Snapshot( every = 100,\n",
    "    dataset_names={raw:\"raw\", labels:\"labels\", mask:\"mask\", gt_affs: \"affs\", gt_affs_mask: \"affS_mask\",prediction:\"prediction\", aff_scale:\"scale\"},\n",
    "    dataset_dtypes={gt_affs: 'float32'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4daeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = gp.Normalize(array= raw) #looks at maximal possible value of your data type and divides by that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e93a3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "deform = gp.DeformAugment(\n",
    "    gp.Coordinate((5100, 5100)),\n",
    "    (340,340),\n",
    "    spatial_dims=2,\n",
    "    #graph_raster_voxel_size=raw_array.voxel_size[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84334dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_augment = gp.IntensityAugment(array=raw, scale_min=0.9, scale_max=1.1, shift_min=-0.1, shift_max=0.1, z_section_wise=False, clip=True)\n",
    "noise = gp.NoiseAugment(array=raw, mode='Gaussian', clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f2a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood = [\n",
    "    (1, 0 ,0),\n",
    "    (0, 1, 0),\n",
    "    (0, 0, 1),\n",
    "    (2, 0, 0),\n",
    "    (0, 5, 0),\n",
    "    (0, 0, 5)\n",
    "]\n",
    "add_affs = gp.AddAffinities(\n",
    "    affinity_neighborhood=neighborhood,\n",
    "    labels=labels,\n",
    "    affinities=gt_affs,\n",
    "    unlabelled=mask,\n",
    "    affinities_mask=gt_affs_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d079f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boundary_issues.model import UNet\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model = torch.nn.Sequential(UNet(\n",
    "    in_channels=1,\n",
    "    num_fmaps=64,\n",
    "    fmap_inc_factor=3,\n",
    "    downsample_factors=[\n",
    "        [1, 2, 2],  \n",
    "        [1, 2, 2]\n",
    "    ],\n",
    "    kernel_size_down=[[(1, 3, 3), (1, 3, 3)],[(1, 3, 3), (1, 3, 3)],[(3, 3, 3), (3, 3, 3)]],\n",
    "    kernel_size_up=[[(3, 3, 3), (3, 3, 3),(3, 3, 3)],[(3, 3, 3), (3, 3, 3), (3, 3, 3)]],\n",
    "    padding=(\"same\", \"valid\", \"valid\"),\n",
    "    voxel_size=(1000, 170, 170),\n",
    "    fov=(1, 1, 1),  \n",
    "    num_fmaps_out=None,\n",
    "    constant_upsample=True\n",
    "), torch.nn.Conv3d(in_channels = 64, out_channels= 6, kernel_size=(1,1,1)),torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "017ca138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")   # add src/ to Python path\n",
    "from boundary_issues.loss import WeightedLoss\n",
    "\n",
    "loss_fn = WeightedLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14ab1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_labels=gp.BalanceLabels(gt_affs,scales=aff_scale, mask= gt_affs_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c97c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train = gp.torch.Train(\n",
    "    model = model,\n",
    "    loss = loss_fn,\n",
    "    optimizer = torch.optim.Adam(model.parameters()),\n",
    "    inputs = {0:raw},\n",
    "    loss_inputs = {0: prediction, 1: gt_affs, 2: gt_affs_mask},\n",
    "    outputs = {0: prediction},\n",
    "    save_every = 200,\n",
    "    log_dir = \"training_logs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    source_raw,\n",
    "    source_labels,\n",
    "    source_mask\n",
    ") + gp.MergeProvider() \n",
    "\n",
    "pipeline += random_location \n",
    "pipeline += normalization \n",
    "pipeline += gp.SimpleAugment(transpose_only=[1,2]) \n",
    "pipeline += deform \n",
    "pipeline += intensity_augment\n",
    "pipeline += noise\n",
    "pipeline += add_affs\n",
    "pipeline += balanced_labels \n",
    "pipeline += gp.Unsqueeze([raw],0)\n",
    "pipeline += gp.Stack(1) \n",
    "pipeline += train \n",
    "pipeline += gp.Squeeze([raw,labels,mask, gt_affs,gt_affs_mask,prediction,aff_scale],0)\n",
    "pipeline += snapshot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f27713cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ArraySource, ArraySource, ArraySource) -> MergeProvider -> RandomLocation -> Normalize -> SimpleAugment -> DeformAugment -> IntensityAugment -> NoiseAugment -> AddAffinities -> BalanceLabels -> Unsqueeze -> Stack -> Train -> Squeeze -> Snapshot\n"
     ]
    }
   ],
   "source": [
    "print (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ae15e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulate a request for \"raw\"\n",
    "\n",
    "input_size = gp.Coordinate((3, 256, 256)) * raw_array.voxel_size\n",
    "output_size = gp.Coordinate((3, 210, 210)) * raw_array.voxel_size\n",
    "\n",
    "request = gp.BatchRequest()\n",
    "\n",
    "request.add(raw, input_size)\n",
    "request.add(labels, output_size)\n",
    "request.add(mask, output_size)\n",
    "request.add(gt_affs, output_size)\n",
    "request.add(gt_affs_mask, output_size)\n",
    "request.add(prediction, output_size)\n",
    "request.add(aff_scale,output_size)\n",
    "\n",
    "# request[raw] = gp.Roi((5000, 119000, 119000), (10000, 85000, 85000)) #always in world units\n",
    "# request[labels] = gp.Roi((5000, 119000, 119000), (10000, 85000, 85000)) #always in world units\n",
    "# request[mask] = gp.Roi((5000, 119000, 119000), (10000, 85000, 85000)) #always in world units\n",
    "# request[gt_affs] = gp.Roi((5000, 119000, 119000), (10000, 85000, 85000)) #always in world units\n",
    "# request[gt_affs_mask] = gp.Roi((5000, 119000, 119000), (10000, 85000, 85000)) #always in world units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afafee75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".Iteration 0: 0.0\n",
      "..................................................Iteration 50: 0.0\n",
      "..................................................Iteration 100: 0.18731670081615448\n",
      "..................................................Iteration 150: 0.2824770510196686\n",
      "..................................................Iteration 200: 0.28001946210861206\n",
      "..................................................Iteration 250: 0.18596245348453522\n",
      "..................................................Iteration 300: 0.20567458868026733\n",
      "..................................................Iteration 350: 0.19245150685310364\n",
      "..................................................Iteration 400: 0.20457245409488678\n",
      "..................................................Iteration 450: 0.6000000238418579\n",
      "..................................................Iteration 500: 0.47669631242752075\n",
      "..................................................Iteration 550: 0.0\n",
      "..................................................Iteration 600: 0.23931720852851868\n",
      "."
     ]
    }
   ],
   "source": [
    "# build the pipeline...\n",
    "with gp.build(pipeline):\n",
    "  for i in range(602):\n",
    "    # ...and request a batch\n",
    "    print(\".\", end=\"\")\n",
    "    batch = pipeline.request_batch(request)\n",
    "    if i%50==0:\n",
    "      print(f\"Iteration {i}: {batch.loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dd24551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): UNet(\n",
      "    (l_conv): ModuleList(\n",
      "      (0): ConvPass(\n",
      "        (conv_pass): Sequential(\n",
      "          (0): Conv3d(1, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "          (1): ReLU()\n",
      "          (2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): ConvPass(\n",
      "        (conv_pass): Sequential(\n",
      "          (0): Conv3d(64, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "          (1): ReLU()\n",
      "          (2): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1))\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): ConvPass(\n",
      "        (conv_pass): Sequential(\n",
      "          (0): Conv3d(192, 576, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "          (1): ReLU()\n",
      "          (2): Conv3d(576, 576, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (l_down): ModuleList(\n",
      "      (0-1): 2 x Downsample(\n",
      "        (down): MaxPool3d(kernel_size=[1, 2, 2], stride=[1, 2, 2], padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (r_up): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0-1): 2 x Upsample(\n",
      "          (up): Upsample(scale_factor=(1.0, 2.0, 2.0), mode='nearest')\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (r_conv): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): ConvPass(\n",
      "          (conv_pass): Sequential(\n",
      "            (0): Conv3d(256, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "            (1): ReLU()\n",
      "            (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "            (3): ReLU()\n",
      "            (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "            (5): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): ConvPass(\n",
      "          (conv_pass): Sequential(\n",
      "            (0): Conv3d(768, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "            (1): ReLU()\n",
      "            (2): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "            (3): ReLU()\n",
      "            (4): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0))\n",
      "            (5): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): Conv3d(64, 6, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boundary_issues",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
